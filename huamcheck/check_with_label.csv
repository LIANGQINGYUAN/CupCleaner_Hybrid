id,old_comment,new_comment,old_code,new_code,score,idx,label
davideas_FlexibleAdapter-19-1905,"always true , if not overridden","always false , if not overridden",protected boolean should activate view while swiping ( ) { return true ; },protected boolean should activate view while swiping ( ) { return false ; },1.0,2513,1
real-logic_aeron-28-1207,"the same as publication # offer ( direct buffer , int , int ) .","the same as publication # offer ( direct buffer , int , int ) when in cluster . state # leader otherwise 1 .","public long offer ( final long correlation id , final direct buffer buffer , final int offset , final int length , final reserved value supplier reserved value supplier ) { session header encoder . correlation id ( correlation id ) ; session header encoder . timestamp ( cluster . time ms ( ) ) ; message buffer . reset ( buffer , offset , length ) ; return response publication . offer ( vectors , reserved value supplier ) ; }","public long offer ( final long correlation id , final direct buffer buffer , final int offset , final int length , final reserved value supplier reserved value supplier ) { if ( cluster . state ( ) ! = cluster . state . leader ) { return num ; } session header encoder . correlation id ( correlation id ) ; session header encoder . timestamp ( cluster . time ms ( ) ) ; message buffer . reset ( buffer , offset , length ) ; return response publication . offer ( vectors , reserved value supplier ) ; }",0.641023576259613,2746,1
eclipse-vertx_vert.x-22-555,the current argument model instance,the current argument instance,public argument model set required ( boolean required ) { this . required = required ; return this ; },public argument set required ( boolean required ) { this . required = required ; return this ; },0.5331626931826273,5139,1
Blankj_AndroidUtilCode-59-152,true : false :,true : success false : fail,"public static boolean install app silent ( final string file path ) { file file = file utils . get file by path ( file path ) ; if ( ! file utils . is file exists ( file ) ) return false ; boolean is root = is device rooted ( ) ; string command = str + file path ; shell utils . command result command result = shell utils . exec cmd ( command , is root ) ; if ( command result . success msg ! = null & & command result . success msg . to lower case ( ) . contains ( str ) ) { return true ; } else { command = str + file path ; command result = shell utils . exec cmd ( command , is root , true ) ; return command result . success msg ! = null & & command result . success msg . to lower case ( ) . contains ( str ) ; } }",public static boolean install app silent ( final string file path ) { return install app silent ( get file by path ( file path ) ) ; },0.30533018459876377,690,0
nicoulaj_idea-markdown-1-6745,todo add javadoc comment .,the psi element matching the element type of the ast node .,@ not null public psi element create element ( astnode node ) { return markdown psi creator . create element ( node ) ; },@ not null public psi element create element ( astnode node ) { return new markdown psi element impl ( node ) ; },0.24528971314430237,3463,0
eclipse-vertx_vert.x-10-545,the result,the resulting sequence,"public cyclic sequence < t > remove ( t element ) { int len = elements . length ; for ( int i = num ; i < len ; i + + ) { if ( objects . equals ( element , elements [ i ] ) ) { if ( len > num ) { object [ ] copy = new object [ len - num ] ; system . arraycopy ( elements , num , copy , num , i ) ; system . arraycopy ( elements , i + num , copy , i , len - i - num ) ; return new cyclic sequence < > ( pos . get ( ) , copy ) ; } else { return new cyclic sequence < > ( ) ; } } } return this ; }","public concurrent cyclic sequence < t > remove ( t element ) { int len = elements . length ; for ( int i = num ; i < len ; i + + ) { if ( objects . equals ( element , elements [ i ] ) ) { if ( len > num ) { object [ ] copy = new object [ len - num ] ; system . arraycopy ( elements , num , copy , num , i ) ; system . arraycopy ( elements , i + num , copy , i , len - i - num ) ; return new concurrent cyclic sequence < > ( pos . get ( ) % copy . length , copy ) ; } else { return new concurrent cyclic sequence < > ( ) ; } } } return this ; }",0.3054082915186882,2246,0
apache_xalan-j-180-5994,object at given index,"value at given index . if that value wasn ' t previously set , the result is undefined for performance reasons . it may throw an exception ( see below ) , may return zero , or ( if set size has previously been used ) may return stale data .",public byte element at ( int i ) { if ( i < m _ blocksize ) return m _ map0 [ i ] ; if ( i > = m _ first free ) return byte . min _ value ; int index = i / m _ blocksize ; int offset = i % m _ blocksize ; byte [ ] block = m _ map [ index ] ; if ( null = = block ) return byte . min _ value ; return block [ offset ] ; },public byte element at ( int i ) { if ( i < m _ blocksize ) return m _ map0 [ i ] ; return m _ map [ i / m _ blocksize ] [ i % m _ blocksize ] ; },0.12590575714906058,2565,0
ReactiveX_RxJava-197-3123,the value returned by the hook,"the value returned by the hook , not null","public static scheduler init io scheduler ( scheduler default scheduler ) { function < scheduler , scheduler > f = on init io handler ; if ( f = = null ) { return default scheduler ; } return apply ( f , default scheduler ) ; }","public static scheduler init io scheduler ( callable < scheduler > default scheduler ) { object helper . require non null ( default scheduler , str ) ; function < callable < scheduler > , scheduler > f = on init io handler ; if ( f = = null ) { return call require non null ( default scheduler ) ; } return apply require non null ( f , default scheduler ) ; }",0.37365303188562393,4302,1
realm_realm-java-150-537,an object,the object found or null if no object matches the query conditions .,public e find first ( ) { realm results < e > result = find all ( ) ; if ( result . size ( ) > num ) { return find all ( ) . get ( num ) ; } else { return null ; } },"public e find first ( ) { long row index = this . query . find ( ) ; if ( row index > = num ) { return realm . get ( clazz , row index ) ; } else { return null ; } }",0.2390751155714194,2925,0
google_closure-templates-292-4677,the input text node with context transitions marked .,the next context transition .,"public static sliced raw text node process raw text ( raw text node raw text node , context context ) throws soy autoescape exception { sliced raw text node sliced raw text node = new sliced raw text node ( raw text node , context ) ; string raw text = raw text node . get raw text ( ) ; int offset = num ; int length = raw text . length ( ) ; while ( offset < length ) { string unprocessed raw text = raw text . substring ( offset ) ; int start offset = offset ; int end offset ; context start context = context ; context end context ; int attr value end = find end of attribute value ( unprocessed raw text , context . delim type ) ; if ( attr value end = = - num ) { raw text context updater cu = new raw text context updater ( ) ; cu . process next token ( raw text node , offset , unprocessed raw text , context ) ; end offset = offset + cu . num chars consumed ; end context = cu . next ; } else { int unprocessed raw text len = unprocessed raw text . length ( ) ; int attr end = attr value end < unprocessed raw text len ? attr value end + context . delim type . text . length ( ) : - num ; string attr value tail = unescape utils . unescape html ( unprocessed raw text . substring ( num , attr value end ) ) ; raw text context updater cu = new raw text context updater ( ) ; context attr context = start context ; while ( attr value tail . length ( ) ! = num ) { cu . process next token ( raw text node , offset , attr value tail , attr context ) ; attr value tail = attr value tail . substring ( cu . num chars consumed ) ; attr context = cu . next ; } if ( attr end ! = - num ) { end offset = offset + attr end ; end context = context . to builder ( ) . with state ( html context . html _ tag ) . without attr context ( ) . build ( ) ; } else { if ( attr value end ! = unprocessed raw text len ) { throw new illegal state exception ( ) ; } end offset = length ; end context = attr context ; } } sliced raw text node . add slice ( start offset , end offset , start context ) ; context = end context ; offset = end offset ; } sliced raw text node . set end context ( context ) ; return sliced raw text node ; }","public static context process raw text ( raw text node raw text node , context context ) throws soy autoescape exception { string raw text = raw text node . get raw text ( ) ; int offset = num ; int length = raw text . length ( ) ; while ( offset < length ) { string unprocessed raw text = raw text . substring ( offset ) ; int end offset ; context start context = context ; context end context ; int attr value end = find end of attribute value ( unprocessed raw text , context . delim type ) ; if ( attr value end = = - num ) { raw text context updater cu = new raw text context updater ( ) ; cu . process next token ( raw text node , offset , unprocessed raw text , context ) ; end offset = offset + cu . num chars consumed ; end context = cu . next ; } else { int unprocessed raw text len = unprocessed raw text . length ( ) ; int attr end = attr value end < unprocessed raw text len ? attr value end + context . delim type . text . length ( ) : - num ; string attr value tail = unescape utils . unescape html ( unprocessed raw text . substring ( num , attr value end ) ) ; raw text context updater cu = new raw text context updater ( ) ; context attr context = start context ; while ( attr value tail . length ( ) ! = num ) { cu . process next token ( raw text node , offset , attr value tail , attr context ) ; attr value tail = attr value tail . substring ( cu . num chars consumed ) ; attr context = cu . next ; } if ( attr end ! = - num ) { end offset = offset + attr end ; end context = context . to builder ( ) . with state ( html context . html _ tag ) . without attr context ( ) . build ( ) ; } else { if ( attr value end ! = unprocessed raw text len ) { throw new illegal state exception ( ) ; } end offset = length ; end context = attr context ; } } context = end context ; offset = end offset ; } return context ; }",0.33188354472319287,405,0
Twitter4J_Twitter4J-3-2528,the value .,the value at the specified location .,public int get int ( int index ) throws jsonexception { object object = get ( index ) ; try { return object instanceof number ? ( ( number ) object ) . int value ( ) : integer . parse int ( ( string ) object ) ; } catch ( exception e ) { throw new jsonexception ( str + index + str ) ; } },"public int get int ( int index ) throws jsonexception { object object = get ( index ) ; integer result = json . to integer ( object ) ; if ( result = = null ) { throw json . type mismatch ( index , object , str ) ; } return result ; }",0.33183664083480835,1822,0
apache_commons-lang-143-3867,always returns false .,"the number of matching characters , zero for no match",public boolean is match ( char ch ) { return false ; },"public int is match ( char [ ] text , int text len , int pos ) { return num ; }",0.3154521584510803,331,0
micronaut-projects_micronaut-core-26-2822,the netty http response,the netty mutable http response,"@ internal public static netty http response get or ( netty http request < ? > request , io . micronaut . http . http response < ? > alternative ) { attribute < netty http response > attr = request . attr ( key ) ; netty http response netty http response = attr . get ( ) ; if ( netty http response = = null ) { netty http response = ( netty http response ) alternative ; attr . set ( netty http response ) ; } return netty http response ; }","@ internal public static netty mutable http response get or ( netty http request < ? > request , io . micronaut . http . http response < ? > alternative ) { attribute < netty mutable http response > attr = request . attr ( key ) ; netty mutable http response netty http response = attr . get ( ) ; if ( netty http response = = null ) { netty http response = ( netty mutable http response ) alternative ; attr . set ( netty http response ) ; } return netty http response ; }",0.5973508755366007,1508,1
OpenAPITools_openapi-generator-9-2920,map,"map & lt ; string , integer & gt ;","public map < string , integer > execute as ( function < response , response > handler ) { type type = new type token < map < string , integer > > ( ) { } . get type ( ) ; return get json ( ) . deserialize ( execute ( handler ) . as string ( ) , type ) ; }","public map < string , integer > execute as ( function < response , response > handler ) { type type = new type token < map < string , integer > > ( ) { } . get type ( ) ; return execute ( handler ) . as ( type ) ; }",0.2785716652870178,691,0
reactor_reactor-core-36-2641,a new timed scheduler,a new time - capable scheduler,"public static timed scheduler new timer ( string name , boolean daemon ) { return new timer ( new scheduler thread factory ( name , daemon , single timed scheduler . counter ) ) ; }","public static scheduler new timer ( string name , boolean daemon ) { return new timer ( new scheduler thread factory ( name , daemon , single scheduler . timer _ counter ) ) ; }",0.5286620954672495,2182,1
ACRA_acra-3-1062,a readable formatted string listing messages retrieved .,an element listing messages retrieved .,"@ non null @ override string collect ( report field report field , report builder report builder ) { try { final drop box manager dropbox = ( drop box manager ) context . get system service ( context . dropbox _ service ) ; final calendar calendar = calendar . get instance ( ) ; calendar . roll ( calendar . minute , - config . dropbox collection minutes ( ) ) ; final long time = calendar . get time in millis ( ) ; date format . format ( calendar . get time ( ) ) ; final list < string > tags = new array list < string > ( ) ; if ( config . include drop box system tags ( ) ) { tags . add all ( arrays . as list ( system _ tags ) ) ; } final set < string > additional tags = config . additional drop box tags ( ) ; if ( ! additional tags . is empty ( ) ) { tags . add all ( additional tags ) ; } if ( tags . is empty ( ) ) { return str ; } final string builder dropbox content = new string builder ( ) ; for ( string tag : tags ) { dropbox content . append ( str ) . append ( tag ) . append ( str ) ; drop box manager . entry entry = dropbox . get next entry ( tag , time ) ; if ( entry = = null ) { dropbox content . append ( str ) . append ( str ) ; continue ; } while ( entry ! = null ) { final long msec = entry . get time millis ( ) ; calendar . set time in millis ( msec ) ; dropbox content . append ( str ) . append ( date format . format ( calendar . get time ( ) ) ) . append ( str ) ; final string text = entry . get text ( num ) ; if ( text ! = null ) { dropbox content . append ( str ) . append ( text ) . append ( str ) ; } else { dropbox content . append ( str ) . append ( str ) ; } entry . close ( ) ; entry = dropbox . get next entry ( tag , msec ) ; } } return dropbox content . to string ( ) ; } catch ( exception e ) { if ( acra . dev _ logging ) acra . log . d ( log _ tag , str ) ; } return acraconstants . not _ available ; }","@ non null @ override element collect ( report field report field , report builder report builder ) { try { final drop box manager dropbox = ( drop box manager ) context . get system service ( context . dropbox _ service ) ; final calendar calendar = calendar . get instance ( ) ; calendar . roll ( calendar . minute , - config . dropbox collection minutes ( ) ) ; final long time = calendar . get time in millis ( ) ; date format . format ( calendar . get time ( ) ) ; final list < string > tags = new array list < string > ( ) ; if ( config . include drop box system tags ( ) ) { tags . add all ( arrays . as list ( system _ tags ) ) ; } final set < string > additional tags = config . additional drop box tags ( ) ; if ( ! additional tags . is empty ( ) ) { tags . add all ( additional tags ) ; } if ( tags . is empty ( ) ) { return acraconstants . not _ available ; } final complex element dropbox content = new complex element ( ) ; for ( string tag : tags ) { final string builder builder = new string builder ( ) ; drop box manager . entry entry = dropbox . get next entry ( tag , time ) ; if ( entry = = null ) { builder . append ( str ) . append ( str ) ; continue ; } while ( entry ! = null ) { final long msec = entry . get time millis ( ) ; calendar . set time in millis ( msec ) ; builder . append ( str ) . append ( date format . format ( calendar . get time ( ) ) ) . append ( str ) ; final string text = entry . get text ( num ) ; if ( text ! = null ) { builder . append ( str ) . append ( text ) . append ( str ) ; } else { builder . append ( str ) . append ( str ) ; } entry . close ( ) ; entry = dropbox . get next entry ( tag , msec ) ; } dropbox content . put ( tag , builder . to string ( ) ) ; } return dropbox content ; } catch ( exception e ) { if ( acra . dev _ logging ) acra . log . d ( log _ tag , str ) ; } return acraconstants . not _ available ; }",0.31715034196774167,974,0
ReactiveX_RxJava-15-25,an observable that emits a boolean value that indicates whether the two sequences are the same,a single that emits a boolean value that indicates whether the two sequences are the same,"@ scheduler support ( scheduler support . none ) public static < t > observable < boolean > sequence equal ( observable source < ? extends t > source1 , observable source < ? extends t > source2 , int buffer size ) { return sequence equal ( source1 , source2 , object helper . equals predicate ( ) , buffer size ) ; }","@ scheduler support ( scheduler support . none ) public static < t > single < boolean > sequence equal ( observable source < ? extends t > source1 , observable source < ? extends t > source2 , int buffer size ) { return sequence equal ( source1 , source2 , object helper . equals predicate ( ) , buffer size ) ; }",0.7986724376678467,3185,1
facebook_buck-232-6253,new instance of builder args .,new instance of build executor args .,public builder args create builder args ( ) { return builder args . builder ( ) . set console ( get console ( ) ) . set buck event bus ( get buck event bus ( ) ) . set platform ( get platform ( ) ) . set clock ( get clock ( ) ) . set root cell ( get cell ( ) ) . set executors ( get executors ( ) ) . set project filesystem factory ( get project filesystem factory ( ) ) . set build info store manager ( get build info store manager ( ) ) . build ( ) ; },public build executor args create builder args ( ) { return build executor args . builder ( ) . set console ( get console ( ) ) . set buck event bus ( get buck event bus ( ) ) . set platform ( get platform ( ) ) . set clock ( get clock ( ) ) . set root cell ( get cell ( ) ) . set executors ( get executors ( ) ) . set project filesystem factory ( get project filesystem factory ( ) ) . set build info store manager ( get build info store manager ( ) ) . build ( ) ; },0.713437557220459,5171,1
apache_hbase-410-7106,the possibly transformed result set to actually return,' has more ' indication to give to client,"public list < key value > post scanner next ( final long scanner id , list < key value > results ) throws ioexception { try { coprocessor lock . read lock ( ) . lock ( ) ; for ( environment env : coprocessors ) { if ( env . impl instanceof region observer ) { results = ( ( region observer ) env . impl ) . post scanner next ( env , scanner id , results ) ; } } return results ; } finally { coprocessor lock . read lock ( ) . unlock ( ) ; } }","public boolean post scanner next ( final internal scanner s , final list < key value > results , final int limit , boolean has more ) throws ioexception { try { coprocessor lock . read lock ( ) . lock ( ) ; for ( environment env : coprocessors ) { if ( env . impl instanceof region observer ) { has more = ( ( region observer ) env . impl ) . post scanner next ( env , s , results , limit , has more ) ; if ( env . should complete ( ) ) { break ; } } } return has more ; } finally { coprocessor lock . read lock ( ) . unlock ( ) ; } }",0.17188996076583862,2473,0
jnorthrup_photon-26-6473,"a new object , to be casted into a set ext",a new object,"public object clone ( ) { return new implication before ( name , ( array list < term > ) clone list ( components ) , ( array list < variable > ) clone list ( open variables ) , ( array list < variable > ) clone list ( closed variables ) , complexity ) ; }","@ override @ suppress warnings ( str ) public object clone ( ) { return new implication before ( name , ( array list < term > ) clone list ( components ) , ( array list < variable > ) clone list ( open variables ) , complexity ) ; }",0.20722259084383646,1366,0
JoanZapata_base-adapter-helper-0-2949,the base view holder for chaining .,the base adapter helper for chaining .,"public base view holder set on item click listener ( int view id , adapter view . on item click listener listener ) { adapter view view = retrieve view ( view id ) ; view . set on item click listener ( listener ) ; return this ; }","public base adapter helper set on item click listener ( int view id , adapter view . on item click listener listener ) { adapter view view = retrieve view ( view id ) ; view . set on item click listener ( listener ) ; return this ; }",1.0,499,1
svn2github_htmlunit-fork-60-5240,the value of the specified attribute,"the value of the specified attribute , null if the attribute is not defined",public string js function _ get attribute ( final string attribute name ) { return get html element or die ( ) . get attribute value ( attribute name ) ; },public string js function _ get attribute ( final string attribute name ) { final string value = get html element or die ( ) . get attribute value ( attribute name ) ; if ( value = = html element . attribute _ not _ defined ) { return null ; } else { return value ; } },0.6016231775283813,550,1
deeplearning4j_deeplearning4j-77-427,ndarray,"ndarray custom separators no longer supported ; use # write txt ( indarray , string ) along with # read txt ( string )","public static indarray read txt ( string file path , string sep ) { file file = new file ( file path ) ; input stream is = null ; try { is = new file input stream ( file ) ; return read txt string ( is , sep ) ; } catch ( file not found exception e ) { throw new runtime exception ( e ) ; } finally { if ( is ! = null ) { try { is . close ( ) ; } catch ( ioexception e ) { e . print stack trace ( ) ; } } } }","@ deprecated public static indarray read txt ( string file path , string sep ) { return read txt ( file path ) ; }",0.27692152683933574,2576,0
vavr-io_vavr-490-1855,a match of type int,"this , the current instance of match .",@ suppress warnings ( str ) public static < r > match . builder < r > caze ( int function < r > function ) { return new match . builder < r > ( ) . caze ( function ) ; },"@ suppress warnings ( str ) public builder < r > caze ( int function < r > function ) { objects . require non null ( function , str ) ; cases . add ( caze ( none . instance ( ) , ( integer i ) - > function . apply ( i ) , integer . class ) ) ; return this ; }",0.28974953293800354,753,0
apache_samza-29-7221,the sink operator spec,the sink operator spec for the send to operator,"public static < m > sink operator spec < m > create send to operator spec ( sink function < m > sink fn , stream graph impl graph , output stream < m > stream ) { return new sink operator spec < > ( sink fn , operator spec . op code . send _ to , graph . get next op id ( ) , stream ) ; }","public static < k , v , m > sink operator spec < m > create send to operator spec ( output stream internal < k , v , m > output stream , int op id ) { return new sink operator spec < > ( output stream , operator spec . op code . send _ to , op id ) ; }",0.6359672347704569,1856,1
real-logic_aeron-15-1201,result of query or null if query was not sent successfully .,result of query .,"public string query for endpoints ( ) { lock . lock ( ) ; try { idle strategy . reset ( ) ; final long correlation id = aeron . next correlation id ( ) ; final long deadline ns = nano clock . nano time ( ) + ctx . message timeout ns ( ) ; final int length = message header encoder . encoded _ length + admin query encoder . block _ length ; int attempts = send _ attempts ; while ( true ) { final long result = publication . try claim ( length , buffer claim ) ; if ( result > num ) { admin query encoder . wrap and apply header ( buffer claim . buffer ( ) , buffer claim . offset ( ) , message header encoder ) . correlation id ( correlation id ) . cluster session id ( cluster session id ) . query type ( admin query type . endpoints ) ; buffer claim . commit ( ) ; final egress poller poller = new egress poller ( subscription , fragment _ limit ) ; while ( true ) { poll next response ( deadline ns , correlation id , poller ) ; if ( poller . correlation id ( ) = = correlation id ) { switch ( poller . event code ( ) ) { case ok : return poller . detail ( ) ; case error : throw new illegal state exception ( poller . detail ( ) ) ; } } } } check result ( result ) ; if ( - - attempts < = num ) { break ; } idle strategy . idle ( ) ; } return null ; } finally { lock . unlock ( ) ; } }","public string query for endpoints ( ) { lock . lock ( ) ; try { final long deadline ns = nano clock . nano time ( ) + ctx . message timeout ns ( ) ; final long correlation id = send admin query ( admin query type . endpoints , deadline ns ) ; final egress poller poller = new egress poller ( subscription , fragment _ limit ) ; while ( true ) { poll next response ( deadline ns , correlation id , poller ) ; if ( poller . correlation id ( ) = = correlation id ) { switch ( poller . event code ( ) ) { case ok : return poller . detail ( ) ; case error : throw new illegal state exception ( poller . detail ( ) ) ; } } } } finally { lock . unlock ( ) ; } }",0.3300410360097885,2416,0
reactor_reactor-core-54-2659,the new flux instannce,the new mono instannce,"public final flux < list < t > > collect sorted list ( comparator < ? super t > comparator , int capacity hint ) { int ch = capacity hint / parallelism ( ) + num ; parallel flux < list < t > > rail reduced = reduce ( ( ) - > new array list < > ( ch ) , ( a , b ) - > { a . add ( b ) ; return a ; } ) ; parallel flux < list < t > > rail sorted = rail reduced . map ( list - > { list . sort ( comparator ) ; return list ; } ) ; flux < list < t > > merged = rail sorted . reduce ( ( a , b ) - > { int n = a . size ( ) + b . size ( ) ; if ( n = = num ) { return new array list < > ( ) ; } list < t > both = new array list < > ( n ) ; iterator < t > at = a . iterator ( ) ; iterator < t > bt = b . iterator ( ) ; t s1 = at . has next ( ) ? at . next ( ) : null ; t s2 = bt . has next ( ) ? bt . next ( ) : null ; while ( s1 ! = null & & s2 ! = null ) { if ( comparator . compare ( s1 , s2 ) < num ) { both . add ( s1 ) ; s1 = at . has next ( ) ? at . next ( ) : null ; } else { both . add ( s2 ) ; s2 = bt . has next ( ) ? bt . next ( ) : null ; } } if ( s1 ! = null ) { both . add ( s1 ) ; while ( at . has next ( ) ) { both . add ( at . next ( ) ) ; } } else if ( s2 ! = null ) { both . add ( s2 ) ; while ( bt . has next ( ) ) { both . add ( bt . next ( ) ) ; } } return both ; } ) ; return merged ; }","public final mono < list < t > > collect sorted list ( comparator < ? super t > comparator , int capacity hint ) { int ch = capacity hint / parallelism ( ) + num ; parallel flux < list < t > > rail reduced = reduce ( ( ) - > new array list < > ( ch ) , ( a , b ) - > { a . add ( b ) ; return a ; } ) ; parallel flux < list < t > > rail sorted = rail reduced . map ( list - > { list . sort ( comparator ) ; return list ; } ) ; mono < list < t > > merged = rail sorted . reduce ( ( a , b ) - > { int n = a . size ( ) + b . size ( ) ; if ( n = = num ) { return new array list < > ( ) ; } list < t > both = new array list < > ( n ) ; iterator < t > at = a . iterator ( ) ; iterator < t > bt = b . iterator ( ) ; t s1 = at . has next ( ) ? at . next ( ) : null ; t s2 = bt . has next ( ) ? bt . next ( ) : null ; while ( s1 ! = null & & s2 ! = null ) { if ( comparator . compare ( s1 , s2 ) < num ) { both . add ( s1 ) ; s1 = at . has next ( ) ? at . next ( ) : null ; } else { both . add ( s2 ) ; s2 = bt . has next ( ) ? bt . next ( ) : null ; } } if ( s1 ! = null ) { both . add ( s1 ) ; while ( at . has next ( ) ) { both . add ( at . next ( ) ) ; } } else if ( s2 ! = null ) { both . add ( s2 ) ; while ( bt . has next ( ) ) { both . add ( bt . next ( ) ) ; } } return both ; } ) ; return merged ; }",0.23916728049516678,5685,0
vavr-io_vavr-263-1741,"this as either if this is a left , left ( null ) if mapper returns an empty iterable , otherwise right ( value ) , where value if the first element of the mapping .",a new right projection,"@ suppress warnings ( str ) @ override default < u > either < l , u > flat map ( function < ? super r , ? extends iterable < ? extends u > > mapper ) { objects . require non null ( mapper , str ) ; if ( is right ( ) ) { return value . get option ( mapper . apply ( get ( ) ) ) . to right ( null ) ; } else { return ( either < l , u > ) this ; } }","@ suppress warnings ( str ) @ override public < u > right projection < l , u > flat map ( function < ? super r , ? extends iterable < ? extends u > > mapper ) { objects . require non null ( mapper , str ) ; if ( either . is right ( ) ) { final iterable < ? extends u > iterable = mapper . apply ( either . get right ( ) ) ; if ( iterable instanceof right projection ) { return ( right projection < l , u > ) iterable ; } else { return either . flat map ( mapper ) . right ( ) ; } } else { return ( right projection < l , u > ) this ; } }",0.4301632046699524,2819,1
mongodb_mongo-java-driver-63-2760,"the object , if found , otherwise null",a document that satisfies the query specified as the argument to this method .,"public dbobject find one ( object obj , dbobject fields ) { return find one ( new basic dbobject ( str , obj ) , fields ) ; }","public dbobject find one ( final object id , final dbobject projection ) { return find one ( new basic dbobject ( str , id ) , projection ) ; }",0.2725219130516052,5450,0
apache_camel-125-5088,an expression object which will return the headers,"an expression object which will return the headers , will be null if the exchange is not out capable .",public static expression out headers expression ( ) { return new expression adapter ( ) { public object evaluate ( exchange exchange ) { return exchange . get out ( ) . get headers ( ) ; } @ override public string to string ( ) { return str ; } } ; },public static expression out headers expression ( ) { return new expression adapter ( ) { public object evaluate ( exchange exchange ) { if ( exchange helper . is out capable ( exchange ) ) { return exchange . get out ( ) . get headers ( ) ; } else { return null ; } } @ override public string to string ( ) { return str ; } } ; },0.609613319238027,3358,1
apereo_cas-0-857,the array as a string with utf - 8 encoding,the new string,"public static string inflate ( final byte [ ] bytes ) { val inflater = new inflater ( true ) ; val xml message bytes = new byte [ inflated _ array _ length ] ; val extended bytes = new byte [ bytes . length + num ] ; system . arraycopy ( bytes , num , extended bytes , num , bytes . length ) ; extended bytes [ bytes . length ] = num ; inflater . set input ( extended bytes ) ; try { val result length = inflater . inflate ( xml message bytes ) ; inflater . end ( ) ; if ( ! inflater . finished ( ) ) { throw new illegal argument exception ( str ) ; } inflater . end ( ) ; return new string ( xml message bytes , num , result length , standard charsets . utf _ 8 ) ; } catch ( final data format exception e ) { logger . trace ( e . get message ( ) , e ) ; return null ; } }","public static string inflate ( final byte [ ] bytes ) { val bais = new byte array input stream ( bytes ) ; val baos = new byte array output stream ( ) ; val buf = new byte [ bytes . length ] ; try ( val iis = new inflater input stream ( bais ) ) { var count = iis . read ( buf ) ; while ( count ! = - num ) { baos . write ( buf , num , count ) ; count = iis . read ( buf ) ; } return new string ( baos . to byte array ( ) , standard charsets . utf _ 8 ) ; } catch ( final exception e ) { return null ; } }",0.24309236307938895,5034,0
apache_commons-lang-271-3916,a value within - 80 and + 20 years from instantiation of this instance,a value between century start ( inclusive ) to century start + 100 ( exclusive ),int adjust year ( final int two digit year ) { final int trial = two digit year + this year - this year % num ; if ( trial < this year + num ) { return trial ; } return trial - num ; },private int adjust year ( final int two digit year ) { int trial = century + two digit year ; return two digit year > = start year ? trial : trial + num ; },0.3210587402184804,5001,0
libgdx_libgdx-20-226,the rectangle represented by the given string .,this rectangle for chaining,"public static rectangle from string ( string v ) { int s0 = v . index of ( str , num ) ; int s1 = v . index of ( str , s0 + num ) ; int s2 = v . index of ( str , s1 + num ) ; if ( s0 ! = - num & & s1 ! = - num & & s2 ! = - num & & v . char at ( num ) = = str & & v . char at ( v . length ( ) - num ) = = str ) { try { float x = float . parse float ( v . substring ( num , s0 ) ) ; float y = float . parse float ( v . substring ( s0 + num , s1 ) ) ; float width = float . parse float ( v . substring ( s1 + num , s2 ) ) ; float height = float . parse float ( v . substring ( s2 + num , v . length ( ) - num ) ) ; return new rectangle ( x , y , width , height ) ; } catch ( number format exception ex ) { } } throw new gdx runtime exception ( str + v ) ; }","public rectangle from string ( string v ) { int s0 = v . index of ( str , num ) ; int s1 = v . index of ( str , s0 + num ) ; int s2 = v . index of ( str , s1 + num ) ; if ( s0 ! = - num & & s1 ! = - num & & s2 ! = - num & & v . char at ( num ) = = str & & v . char at ( v . length ( ) - num ) = = str ) { try { float x = float . parse float ( v . substring ( num , s0 ) ) ; float y = float . parse float ( v . substring ( s0 + num , s1 ) ) ; float width = float . parse float ( v . substring ( s1 + num , s2 ) ) ; float height = float . parse float ( v . substring ( s2 + num , v . length ( ) - num ) ) ; return this . set ( x , y , width , height ) ; } catch ( number format exception ex ) { } } throw new gdx runtime exception ( str + v ) ; }",0.4043024182319641,3073,1
apache_cocoon-46-5747,description of the returned value,"true if crawling has finished , else false .",public boolean has next ( ) { return cocoon crawler . urls to process . size ( ) > num ; },public boolean has next ( ) { return cocoon crawler . urls to process . size ( ) > num | | cocoon crawler . urls next depth . size ( ) > num ; },0.2798727750778198,5191,0
apache_lucene-solr-45-2431,the distance metric .,"the distance metric , in aggregation form .","public double path distance ( final planet model planet model , final distance style distance style , final double x , final double y , final double z ) { if ( ! is within ( x , y , z ) ) return double . positive _ infinity ; final double perp x = normalized connecting plane . y * z - normalized connecting plane . z * y ; final double perp y = normalized connecting plane . z * x - normalized connecting plane . x * z ; final double perp z = normalized connecting plane . x * y - normalized connecting plane . y * x ; final double magnitude = math . sqrt ( perp x * perp x + perp y * perp y + perp z * perp z ) ; if ( math . abs ( magnitude ) < vector . minimum _ resolution ) return distance style . compute distance ( start , x , y , z ) ; final double norm factor = num / magnitude ; final plane normalized perp plane = new plane ( perp x * norm factor , perp y * norm factor , perp z * norm factor , num ) ; final geo point [ ] intersection points = normalized connecting plane . find intersections ( planet model , normalized perp plane ) ; geo point the point ; if ( intersection points . length = = num ) throw new runtime exception ( str + x + str + y + str + z ) ; else if ( intersection points . length = = num ) the point = intersection points [ num ] ; else { if ( start cutoff plane . is within ( intersection points [ num ] ) & & end cutoff plane . is within ( intersection points [ num ] ) ) the point = intersection points [ num ] ; else if ( start cutoff plane . is within ( intersection points [ num ] ) & & end cutoff plane . is within ( intersection points [ num ] ) ) the point = intersection points [ num ] ; else throw new runtime exception ( str + x + str + y + str + z ) ; } return distance style . compute distance ( the point , x , y , z ) + distance style . compute distance ( start , the point . x , the point . y , the point . z ) ; }","public double path distance ( final planet model planet model , final distance style distance style , final double x , final double y , final double z ) { if ( ! is within ( x , y , z ) ) return double . positive _ infinity ; final double perp x = normalized connecting plane . y * z - normalized connecting plane . z * y ; final double perp y = normalized connecting plane . z * x - normalized connecting plane . x * z ; final double perp z = normalized connecting plane . x * y - normalized connecting plane . y * x ; final double magnitude = math . sqrt ( perp x * perp x + perp y * perp y + perp z * perp z ) ; if ( math . abs ( magnitude ) < vector . minimum _ resolution ) return distance style . to aggregation form ( distance style . compute distance ( start , x , y , z ) ) ; final double norm factor = num / magnitude ; final plane normalized perp plane = new plane ( perp x * norm factor , perp y * norm factor , perp z * norm factor , num ) ; final geo point [ ] intersection points = normalized connecting plane . find intersections ( planet model , normalized perp plane ) ; geo point the point ; if ( intersection points . length = = num ) throw new runtime exception ( str + x + str + y + str + z ) ; else if ( intersection points . length = = num ) the point = intersection points [ num ] ; else { if ( start cutoff plane . is within ( intersection points [ num ] ) & & end cutoff plane . is within ( intersection points [ num ] ) ) the point = intersection points [ num ] ; else if ( start cutoff plane . is within ( intersection points [ num ] ) & & end cutoff plane . is within ( intersection points [ num ] ) ) the point = intersection points [ num ] ; else throw new runtime exception ( str + x + str + y + str + z ) ; } return distance style . aggregate distances ( distance style . to aggregation form ( distance style . compute distance ( the point , x , y , z ) ) , distance style . to aggregation form ( distance style . compute distance ( start , the point . x , the point . y , the point . z ) ) ) ; }",0.47363148132960003,1952,1
apache_manifoldcf-65-4782,"true if the resource exists , false otherwise .","read status - either found , not found , or bad args","public static boolean execute read command ( ithread context tc , configuration output , string path , map < string , list < string > > query parameters ) throws manifold cfexception { if ( path . equals ( str ) ) { return api read jobs ( tc , output ) ; } else if ( path . starts with ( str ) ) { long job id = new long ( path . substring ( str . length ( ) ) ) ; return api read job ( tc , output , job id ) ; } else if ( path . starts with ( str ) ) { int first separator = str . length ( ) ; string connection name = decode apipath element ( path . substring ( first separator ) ) ; return api read repository connection history ( tc , output , connection name , query parameters ) ; } else if ( path . starts with ( str ) ) { int first separator = str . length ( ) ; int second separator = path . index of ( str , first separator ) ; if ( second separator = = - num ) { create error node ( output , str ) ; return false ; } string connection type = path . substring ( first separator , second separator ) ; string connection name = decode apipath element ( path . substring ( second separator + num ) ) ; if ( connection type . equals ( str ) ) { return api read output connection status ( tc , output , connection name ) ; } else if ( connection type . equals ( str ) ) { return api read authority connection status ( tc , output , connection name ) ; } else if ( connection type . equals ( str ) ) { return api read repository connection status ( tc , output , connection name ) ; } else { create error node ( output , str + connection type + str ) ; return false ; } } else if ( path . starts with ( str ) ) { int first separator = str . length ( ) ; int second separator = path . index of ( str , first separator ) ; if ( second separator = = - num ) { create error node ( output , str ) ; return false ; } int third separator = path . index of ( str , second separator + num ) ; if ( third separator = = - num ) { create error node ( output , str ) ; return false ; } string connection type = path . substring ( first separator , second separator ) ; string connection name = decode apipath element ( path . substring ( second separator + num , third separator ) ) ; string command = path . substring ( third separator + num ) ; if ( connection type . equals ( str ) ) { return api read output connection info ( tc , output , connection name , command ) ; } else if ( connection type . equals ( str ) ) { return api read repository connection info ( tc , output , connection name , command ) ; } else { create error node ( output , str + connection type + str ) ; return false ; } } else if ( path . equals ( str ) ) { return api read job statuses ( tc , output ) ; } else if ( path . starts with ( str ) ) { long job id = new long ( path . substring ( str . length ( ) ) ) ; return api read job status ( tc , output , job id ) ; } else if ( path . starts with ( str ) ) { long job id = new long ( path . substring ( str . length ( ) ) ) ; return api read job status no counts ( tc , output , job id ) ; } else if ( path . equals ( str ) ) { return api read output connections ( tc , output ) ; } else if ( path . starts with ( str ) ) { string connection name = decode apipath element ( path . substring ( str . length ( ) ) ) ; return api read output connection ( tc , output , connection name ) ; } else if ( path . equals ( str ) ) { return api read authority connections ( tc , output ) ; } else if ( path . starts with ( str ) ) { string connection name = decode apipath element ( path . substring ( str . length ( ) ) ) ; return api read authority connection ( tc , output , connection name ) ; } else if ( path . equals ( str ) ) { return api read repository connections ( tc , output ) ; } else if ( path . starts with ( str ) ) { string connection name = decode apipath element ( path . substring ( str . length ( ) ) ) ; return api read repository connection ( tc , output , connection name ) ; } else if ( path . equals ( str ) ) { return api read output connectors ( tc , output ) ; } else if ( path . equals ( str ) ) { return api read authority connectors ( tc , output ) ; } else if ( path . equals ( str ) ) { return api read repository connectors ( tc , output ) ; } else { create error node ( output , str ) ; return false ; } }","public static int execute read command ( ithread context tc , configuration output , string path , map < string , list < string > > query parameters ) throws manifold cfexception { if ( path . equals ( str ) ) { return api read jobs ( tc , output ) ; } else if ( path . starts with ( str ) ) { long job id = new long ( path . substring ( str . length ( ) ) ) ; return api read job ( tc , output , job id ) ; } else if ( path . starts with ( str ) ) { int first separator = str . length ( ) ; string connection name = decode apipath element ( path . substring ( first separator ) ) ; return api read repository connection history ( tc , output , connection name , query parameters ) ; } else if ( path . starts with ( str ) ) { int first separator = str . length ( ) ; int second separator = path . index of ( str , first separator ) ; if ( second separator = = - num ) { create error node ( output , str ) ; return readresult _ notfound ; } string connection type = path . substring ( first separator , second separator ) ; string connection name = decode apipath element ( path . substring ( second separator + num ) ) ; if ( connection type . equals ( str ) ) { return api read output connection status ( tc , output , connection name ) ; } else if ( connection type . equals ( str ) ) { return api read authority connection status ( tc , output , connection name ) ; } else if ( connection type . equals ( str ) ) { return api read repository connection status ( tc , output , connection name ) ; } else { create error node ( output , str + connection type + str ) ; return readresult _ notfound ; } } else if ( path . starts with ( str ) ) { int first separator = str . length ( ) ; int second separator = path . index of ( str , first separator ) ; if ( second separator = = - num ) { create error node ( output , str ) ; return readresult _ notfound ; } int third separator = path . index of ( str , second separator + num ) ; if ( third separator = = - num ) { create error node ( output , str ) ; return readresult _ notfound ; } string connection type = path . substring ( first separator , second separator ) ; string connection name = decode apipath element ( path . substring ( second separator + num , third separator ) ) ; string command = path . substring ( third separator + num ) ; if ( connection type . equals ( str ) ) { return api read output connection info ( tc , output , connection name , command ) ; } else if ( connection type . equals ( str ) ) { return api read repository connection info ( tc , output , connection name , command ) ; } else { create error node ( output , str + connection type + str ) ; return readresult _ notfound ; } } else if ( path . equals ( str ) ) { return api read job statuses ( tc , output ) ; } else if ( path . starts with ( str ) ) { long job id = new long ( path . substring ( str . length ( ) ) ) ; return api read job status ( tc , output , job id ) ; } else if ( path . starts with ( str ) ) { long job id = new long ( path . substring ( str . length ( ) ) ) ; return api read job status no counts ( tc , output , job id ) ; } else if ( path . equals ( str ) ) { return api read output connections ( tc , output ) ; } else if ( path . starts with ( str ) ) { string connection name = decode apipath element ( path . substring ( str . length ( ) ) ) ; return api read output connection ( tc , output , connection name ) ; } else if ( path . equals ( str ) ) { return api read authority connections ( tc , output ) ; } else if ( path . starts with ( str ) ) { string connection name = decode apipath element ( path . substring ( str . length ( ) ) ) ; return api read authority connection ( tc , output , connection name ) ; } else if ( path . equals ( str ) ) { return api read repository connections ( tc , output ) ; } else if ( path . starts with ( str ) ) { string connection name = decode apipath element ( path . substring ( str . length ( ) ) ) ; return api read repository connection ( tc , output , connection name ) ; } else if ( path . equals ( str ) ) { return api read output connectors ( tc , output ) ; } else if ( path . equals ( str ) ) { return api read authority connectors ( tc , output ) ; } else if ( path . equals ( str ) ) { return api read repository connectors ( tc , output ) ; } else { create error node ( output , str ) ; return readresult _ notfound ; } }",0.30559951066970825,6349,0
alanma_Xydra-7-5766,the new xboolean list value which the specified boolean was removed from ( null if the given field had no xboolean list value ),the new xboolean list value which the specified boolean was removed from ( null if the given xfield had no xboolean list value ),"public static xboolean list value remove boolean from list ( xid actor id , xfield field , int index ) { xvalue value = field . get value ( ) ; if ( value instanceof xboolean list value ) { xboolean list value list value = ( xboolean list value ) value ; list < boolean > list = xx . as list ( list value ) ; list . remove ( index ) ; list value = to boolean list value ( list ) ; field . set value ( actor id , list value ) ; return list value ; } else { return null ; } }","public static xboolean list value remove boolean from list ( xid actor id , xfield field , int index ) { xvalue value = field . get value ( ) ; if ( value = = null ) { return null ; } if ( value instanceof xboolean list value ) { xboolean list value list value = ( xboolean list value ) value ; list < boolean > list = xx . as list ( list value ) ; list . remove ( index ) ; list value = to boolean list value ( list ) ; field . set value ( actor id , list value ) ; return list value ; } else { return null ; } }",0.8040183385213217,781,1
davideas_FlexibleAdapter-1-1892,a new instance of bottom sheet dialog,a new instance of bottom sheet section dialog,"public static bottom sheet dialog new instance ( @ layout res int layout res id ) { return new instance ( layout res id , null ) ; }","public static bottom sheet section dialog new instance ( @ layout res int layout res id ) { return new instance ( layout res id , null ) ; }",1.0,3607,1
vavr-io_vavr-502-1860,a match of type t,"this , the current instance of match .","public static < r > match . builder < r > caze ( 1 < ? , r > function ) { return new match . builder < r > ( ) . caze ( function ) ; }","public builder < r > caze ( 1 < ? , r > function ) { objects . require non null ( function , str ) ; cases . add ( caze ( none . instance ( ) , function ) ) ; return this ; }",0.33318227032820386,4034,0
apache_systemml-194-6832,true if a builtin function was found,expression if found otherwise null,"protected boolean build for built in function ( parser rule context ctx , string function name , array list < parameter expression > param expressions , action f ) { try { if ( functions . contains ( function name ) ) { return false ; } expression lsf = handle language specific function ( ctx , function name , param expressions ) ; if ( lsf ! = null ) { set file line column ( lsf , ctx ) ; f . execute ( lsf ) ; return true ; } builtin function expression bife = builtin function expression . get builtin function expression ( ctx , function name , param expressions , current file ) ; if ( bife ! = null ) { f . execute ( bife ) ; return true ; } parameterized builtin function expression pbife = parameterized builtin function expression . get param builtin function expression ( ctx , function name , param expressions , current file ) ; if ( pbife ! = null ) { f . execute ( pbife ) ; return true ; } data expression dbife = data expression . get data expression ( ctx , function name , param expressions , current file , error listener ) ; if ( dbife ! = null ) { f . execute ( dbife ) ; return true ; } } catch ( exception e ) { notify error listeners ( str + function name + str + e . get message ( ) , ctx . start ) ; return true ; } return false ; }","protected expression build for built in function ( parser rule context ctx , string function name , array list < parameter expression > param expressions ) { try { if ( functions . contains ( function name ) ) { return null ; } expression lsf = handle language specific function ( ctx , function name , param expressions ) ; if ( lsf ! = null ) { set file line column ( lsf , ctx ) ; return lsf ; } builtin function expression bife = builtin function expression . get builtin function expression ( ctx , function name , param expressions , current file ) ; if ( bife ! = null ) { return bife ; } parameterized builtin function expression pbife = parameterized builtin function expression . get param builtin function expression ( ctx , function name , param expressions , current file ) ; if ( pbife ! = null ) { return pbife ; } data expression dbife = data expression . get data expression ( ctx , function name , param expressions , current file , error listener ) ; if ( dbife ! = null ) { return dbife ; } } catch ( exception e ) { notify error listeners ( str + function name + str + e . get message ( ) , ctx . start ) ; } return null ; }",0.2841675380865733,5897,0
springfox_springfox-8-1380,this swagger spring mvc plugin,this documentation configurer,public swagger spring mvc plugin ignored parameter types ( class . . . classes ) { this . ignorable parameter types . add all ( arrays . as list ( classes ) ) ; return this ; },public documentation configurer ignored parameter types ( class . . . classes ) { this . ignorable parameter types . add all ( arrays . as list ( classes ) ) ; return this ; },0.2767585913340251,21,0
deeplearning4j_deeplearning4j-132-449,ndarray,an ndarray read from a text file,"public static indarray read txt ( string file path ) { int line num = num ; int row num = num ; int tensor num = num ; char the order = str ; int [ ] the shape = { num , num } ; int rank = num ; double [ ] [ ] subset arr = { { num , num } , { num , num } } ; indarray new arr = nd4j . zeros ( num , num ) ; try { file txt file = new file ( file path ) ; line iterator it = file utils . line iterator ( txt file ) ; try { while ( it . has next ( ) ) { string line = it . next line ( ) ; line num + + ; line = line . replace all ( str , str ) ; if ( line . equals ( str ) | | line . equals ( str ) ) continue ; if ( line num = = num ) { string [ ] line arr = line . split ( str ) ; string file source = line arr [ num ] . replace all ( str , str ) ; if ( ! file source . equals ( str ) ) return null ; } if ( line num = = num ) { string [ ] line arr = line . split ( str ) ; the order = line arr [ num ] . replace ( str , str ) . char at ( num ) ; continue ; } if ( line num = = num ) { string [ ] line arr = line . split ( str ) ; string drop json comma = line arr [ num ] . split ( str ) [ num ] ; string [ ] shape string = drop json comma . replace ( str , str ) . split ( str ) ; rank = shape string . length ; the shape = new int [ rank ] ; for ( int i = num ; i < rank ; i + + ) { try { the shape [ i ] = integer . parse int ( shape string [ i ] ) ; } catch ( number format exception nfe ) { } ; } subset arr = new double [ the shape [ rank - num ] ] [ the shape [ rank - num ] ] ; new arr = nd4j . zeros ( the shape , the order ) ; continue ; } if ( line num > num ) { string [ ] entries = line . replace ( str , str ) . replace all ( str , str ) . replace all ( str , str ) . split ( str ) ; for ( int i = num ; i < the shape [ rank - num ] ; i + + ) { try { subset arr [ row num ] [ i ] = double . parse double ( entries [ i ] ) ; } catch ( number format exception nfe ) { } } row num + + ; if ( row num = = the shape [ rank - num ] ) { indarray sub tensor = nd4j . create ( subset arr ) ; new arr . tensor along dimension ( tensor num , rank - num , rank - num ) . addi ( sub tensor ) ; row num = num ; tensor num + + ; } } } } finally { line iterator . close quietly ( it ) ; } } catch ( ioexception e ) { throw new runtime exception ( str , e ) ; } return new arr ; }","public static indarray read txt ( string file path ) { return read txt ( file path , str ) ; }",0.3322344894210498,1054,0
stephenh_google-web-toolkit-219-4265,the banner,the navigator,public list box place picker view < expenses list place > get places box ( ) { return places box ; },public place picker view < list scaffold place > get places box ( ) { return places box ; },0.1980710302790006,3610,0
pushtorefresh_storio-38-2305,"non - null observable which will emit non - null list with mapped results , list can be empty",non - null observable which will emit non - null list with mapped results and will be subscribed to changes of # query uri,@ non null @ override public observable < list < t > > create observable ( ) { throw exception if rx java is not available ( str ) ; return observable . create ( on subscribe execute as blocking . new instance ( this ) ) ; },@ non null @ override public observable < list < t > > create observable ( ) { throw exception if rx java is not available ( str ) ; return stor iocontent resolver . observe changes of uri ( query . uri ) . map ( map something to execute as blocking . new instance ( this ) ) . start with ( execute as blocking ( ) ) ; },0.504603256781896,3228,1
google_ExoPlayer-604-4829,this builder .,"this factory , for convenience .",public builder set live presentation delay ms ( long live presentation delay ms ) { this . live presentation delay ms = live presentation delay ms ; return this ; },public factory set live presentation delay ms ( long live presentation delay ms ) { assertions . check state ( ! is create called ) ; this . live presentation delay ms = live presentation delay ms ; return this ; },0.33319465319315594,3868,0
apache_hbase-108-2211,number of cleaned regions,number of archiving jobs started .,"int scan ( ) throws ioexception { try { if ( ! already running . compare and set ( false , true ) ) { log . debug ( str ) ; return num ; } triple < integer , map < hregion info , result > , map < hregion info , result > > scan triple = get merged regions and split parents ( ) ; int count = scan triple . get first ( ) ; int merge cleaned = num ; map < hregion info , result > merged regions = scan triple . get second ( ) ; for ( map . entry < hregion info , result > e : merged regions . entry set ( ) ) { if ( this . services . is in maintenance mode ( ) ) { break ; } pair of same type < hregion info > p = meta table accessor . get merge regions ( e . get value ( ) ) ; hregion info region a = p . get first ( ) ; hregion info region b = p . get second ( ) ; if ( region a = = null | | region b = = null ) { log . warn ( str + ( region a = = null ? str : region a . get region name as string ( ) ) + str + ( region b = = null ? str : region b . get region name as string ( ) ) + str + e . get key ( ) . get region name as string ( ) ) ; } else { if ( clean merge region ( e . get key ( ) , region a , region b ) ) { merge cleaned + + ; } } } map < hregion info , result > split parents = scan triple . get third ( ) ; int split cleaned = num ; hash set < string > parent not cleaned = new hash set < > ( ) ; for ( map . entry < hregion info , result > e : split parents . entry set ( ) ) { if ( this . services . is in maintenance mode ( ) ) { break ; } if ( ! parent not cleaned . contains ( e . get key ( ) . get encoded name ( ) ) & & clean parent ( e . get key ( ) , e . get value ( ) ) ) { split cleaned + + ; } else { pair of same type < hregion info > daughters = meta table accessor . get daughter regions ( e . get value ( ) ) ; parent not cleaned . add ( daughters . get first ( ) . get encoded name ( ) ) ; parent not cleaned . add ( daughters . get second ( ) . get encoded name ( ) ) ; } } if ( ( merge cleaned + split cleaned ) ! = num ) { log . info ( str + count + str + merge cleaned + str + split cleaned + str ) ; } else if ( log . is trace enabled ( ) ) { log . trace ( str + count + str + merge cleaned + str + split cleaned + str ) ; } return merge cleaned + split cleaned ; } finally { already running . set ( false ) ; } }","int scan ( ) throws ioexception { int result = num ; try { if ( ! already running . compare and set ( false , true ) ) { log . debug ( str ) ; return result ; } triple < integer , map < hregion info , result > , map < hregion info , result > > scan triple = get merged regions and split parents ( ) ; map < hregion info , result > merged regions = scan triple . get second ( ) ; for ( map . entry < hregion info , result > e : merged regions . entry set ( ) ) { if ( this . services . is in maintenance mode ( ) ) { break ; } pair of same type < hregion info > p = meta table accessor . get merge regions ( e . get value ( ) ) ; hregion info region a = p . get first ( ) ; hregion info region b = p . get second ( ) ; if ( region a = = null | | region b = = null ) { log . warn ( str + ( region a = = null ? str : region a . get short name to log ( ) ) + str + ( region b = = null ? str : region b . get short name to log ( ) ) + str + e . get key ( ) . get short name to log ( ) ) ; } else { if ( clean merge region ( e . get key ( ) , region a , region b ) ) { result + + ; } } } map < hregion info , result > split parents = scan triple . get third ( ) ; hash set < string > parent not cleaned = new hash set < > ( ) ; for ( map . entry < hregion info , result > e : split parents . entry set ( ) ) { if ( this . services . is in maintenance mode ( ) ) { break ; } if ( ! parent not cleaned . contains ( e . get key ( ) . get encoded name ( ) ) & & clean parent ( e . get key ( ) , e . get value ( ) ) ) { result + + ; } else { pair of same type < hregion info > daughters = meta table accessor . get daughter regions ( e . get value ( ) ) ; parent not cleaned . add ( daughters . get first ( ) . get encoded name ( ) ) ; parent not cleaned . add ( daughters . get second ( ) . get encoded name ( ) ) ; } } return result ; } finally { already running . set ( false ) ; } }",0.21150842557350794,4006,0
apache_flink-923-7186,the connected data stream .,the connected streams .,"public < r > connected data stream < t , r > connect ( data stream < r > data stream ) { return new connected data stream < t , r > ( environment , this , data stream ) ; }","public < r > connected streams < t , r > connect ( data stream < r > data stream ) { return new connected streams < t , r > ( environment , this , data stream ) ; }",0.7325498660405477,2916,1
OpenAPITools_openapi-generator-95-2944,java . util . map,map,"public java . util . map < string , integer > get inventory ( ) throws api exception { object post body = null ; string path = str . replace all ( str , str ) ; java . util . list < pair > query params = new java . util . array list < pair > ( ) ; java . util . map < string , string > header params = new java . util . hash map < string , string > ( ) ; java . util . map < string , object > form params = new java . util . hash map < string , object > ( ) ; final string [ ] accepts = { str , str } ; final string accept = api client . select header accept ( accepts ) ; final string [ ] content types = { } ; final string content type = api client . select header content type ( content types ) ; string [ ] auth names = new string [ ] { str } ; type ref return type = new type ref < java . util . map < string , integer > > ( ) { } ; return api client . invoke api ( path , str , query params , post body , header params , form params , accept , content type , auth names , return type ) ; }","public map < string , integer > get inventory ( ) throws api exception { object post body = null ; string path = str . replace all ( str , str ) ; list < pair > query params = new array list < pair > ( ) ; map < string , string > header params = new hash map < string , string > ( ) ; map < string , object > form params = new hash map < string , object > ( ) ; final string [ ] accepts = { str , str } ; final string accept = api client . select header accept ( accepts ) ; final string [ ] content types = { } ; final string content type = api client . select header content type ( content types ) ; string [ ] auth names = new string [ ] { str } ; type ref return type = new type ref < map < string , integer > > ( ) { } ; return api client . invoke api ( path , str , query params , post body , header params , form params , accept , content type , auth names , return type ) ; }",0.1601260987420877,5333,0
sonatype_sisu-18-7314,qualified bean entry,qualified bean,"private entry < q , t > extract qualified bean ( final int index ) { if ( exposed ) { beans = new array list < deferred bean entry < q , t > > ( beans ) ; exposed = false ; } final deferred bean entry < q , t > bean = beans . remove ( index ) ; if ( default _ qualifier . equals ( bean . get key ( ) ) ) { default index - - ; } return bean ; }","private qualified bean < q , t > extract qualified bean ( final int index ) { if ( exposed ) { beans = new array list < qualified bean < q , t > > ( beans ) ; exposed = false ; } final qualified bean < q , t > bean = beans . remove ( index ) ; if ( default _ qualifier . equals ( bean . get key ( ) ) ) { default index - - ; } return bean ; }",0.5303645531336466,5789,1
spring-projects_spring-framework-356-3422,an object or null,a response entity instance,"protected object handle missing servlet request part ( missing servlet request part exception ex , http headers headers , http status status , web request request ) { return handle exception internal ( ex , headers , status , request ) ; }","protected response entity < object > handle missing servlet request part ( missing servlet request part exception ex , http headers headers , http status status , web request request ) { return handle exception internal ( ex , null , headers , status , request ) ; }",0.23428339014450708,1243,0
apache_commons-math-664-4639,this instance .,a new instance .,public levenberg marquardt optimizer with cost relative tolerance ( double new cost relative tolerance ) { this . cost relative tolerance = new cost relative tolerance ; return self ( ) ; },"public levenberg marquardt optimizer with cost relative tolerance ( double cost relative tolerance ) { return new levenberg marquardt optimizer ( initial step bound factor , cost relative tolerance , par relative tolerance , ortho tolerance , qr ranking threshold ) ; }",0.286037128418684,2284,0
codehaus_groovy-git-194-4811,a list,the resulting collection,"public static list plus ( collection left , object right ) { list answer = new array list ( left . size ( ) + num ) ; answer . add all ( left ) ; answer . add ( right ) ; return answer ; }","public static collection plus ( collection left , object right ) { collection answer ; if ( left instanceof set ) answer = new hash set ( ) ; else answer = new array list ( left . size ( ) + num ) ; answer . add all ( left ) ; answer . add ( right ) ; return answer ; }",0.3190051317214966,3161,0
jvalkeal_spring-yarn-12-7486,holder containing response,the find running job executions res,"private mind rpc message holder handle find running job executions ( mind rpc message holder holder ) { mind rpc message holder out holder = null ; try { find running job executions req request = job repository rpc factory . convert ( holder , find running job executions req . class ) ; set < job execution > job executions = job execution dao . find running job executions ( request . job name ) ; find running job executions res response = new find running job executions res ( ) ; response . job executions = new hash set < job execution type > ( ) ; for ( job execution job execution : job executions ) { response . job executions . add ( job repository rpc factory . build job execution type ( job execution ) ) ; } byte [ ] bytes = mapper . write value as bytes ( response ) ; out holder = new mind rpc message holder ( null , bytes ) ; } catch ( exception e ) { log . error ( str , e ) ; } return out holder ; }","private find running job executions res handle find running job executions ( find running job executions req request ) { find running job executions res response = null ; try { set < job execution > job executions = job execution dao . find running job executions ( request . job name ) ; response = new find running job executions res ( ) ; response . job executions = new hash set < job execution type > ( ) ; for ( job execution job execution : job executions ) { response . job executions . add ( job repository rpc factory . build job execution type ( job execution ) ) ; } } catch ( exception e ) { log . error ( str , e ) ; } return response ; }",0.2931911249955495,4333,0
brianfrankcooper_YCSB-24-2373,"zero on success , a non - zero error code on error",the result of the operation .,"public int delete ( string table , string key ) { long ist = _ measurements . get intendedtart time ns ( ) ; long st = system . nano time ( ) ; int res = _ db . delete ( table , key ) ; long en = system . nano time ( ) ; measure ( str , ist , st , en ) ; _ measurements . report return code ( str , res ) ; return res ; }","public status delete ( string table , string key ) { long ist = _ measurements . get intendedtart time ns ( ) ; long st = system . nano time ( ) ; status res = _ db . delete ( table , key ) ; long en = system . nano time ( ) ; measure ( str , res , ist , st , en ) ; _ measurements . report status ( str , res ) ; return res ; }",0.18351844449838003,1244,0
elastic_elasticsearch-7-10,the local checkpoint on the target,the send snapshot result,"long phase2 ( final long starting seq no , long required seq no range start , long ending seq no , final translog . snapshot snapshot , final long max seen auto id timestamp , final long max seq no of updates or deletes ) throws ioexception { if ( shard . state ( ) = = index shard state . closed ) { throw new index shard closed exception ( request . shard id ( ) ) ; } cancellable threads . check for cancel ( ) ; final stop watch stop watch = new stop watch ( ) . start ( ) ; logger . trace ( str + starting seq no + str + str + required seq no range start + str + ending seq no + str ) ; final send snapshot result result = send snapshot ( starting seq no , required seq no range start , ending seq no , snapshot , max seen auto id timestamp , max seq no of updates or deletes ) ; stop watch . stop ( ) ; logger . trace ( str , stop watch . total time ( ) ) ; response . phase2 time = stop watch . total time ( ) . millis ( ) ; response . phase2 operations = result . total operations ; return result . target local checkpoint ; }","send snapshot result phase2 ( long starting seq no , long required seq no range start , long ending seq no , translog . snapshot snapshot , long max seen auto id timestamp , long max seq no of updates or deletes ) throws ioexception { assert required seq no range start < = ending seq no + num : str + required seq no range start + str + ending seq no ; assert starting seq no < = required seq no range start : str + starting seq no + str + required seq no range start ; if ( shard . state ( ) = = index shard state . closed ) { throw new index shard closed exception ( request . shard id ( ) ) ; } final stop watch stop watch = new stop watch ( ) . start ( ) ; logger . trace ( str + starting seq no + str + str + required seq no range start + str + ending seq no + str ) ; int ops = num ; long size = num ; int skipped ops = num ; int total sent ops = num ; final atomic long target local checkpoint = new atomic long ( sequence numbers . unassigned _ seq _ no ) ; final list < translog . operation > operations = new array list < > ( ) ; final local checkpoint tracker required ops tracker = new local checkpoint tracker ( ending seq no , required seq no range start - num ) ; final int expected total ops = snapshot . total operations ( ) ; if ( expected total ops = = num ) { logger . trace ( str ) ; } final cancellable threads . iointerruptible send batch = ( ) - > { final long target checkpoint = recovery target . index translog operations ( operations , expected total ops , max seen auto id timestamp , max seq no of updates or deletes ) ; target local checkpoint . set ( target checkpoint ) ; } ; translog . operation operation ; while ( ( operation = snapshot . next ( ) ) ! = null ) { if ( shard . state ( ) = = index shard state . closed ) { throw new index shard closed exception ( request . shard id ( ) ) ; } cancellable threads . check for cancel ( ) ; final long seq no = operation . seq no ( ) ; if ( seq no < starting seq no | | seq no > ending seq no ) { skipped ops + + ; continue ; } operations . add ( operation ) ; ops + + ; size + = operation . estimate size ( ) ; total sent ops + + ; required ops tracker . mark seq no as completed ( seq no ) ; if ( size > = chunk size in bytes ) { cancellable threads . execute io ( send batch ) ; logger . trace ( str , ops , new byte size value ( size ) , expected total ops ) ; ops = num ; size = num ; operations . clear ( ) ; } } if ( ! operations . is empty ( ) | | total sent ops = = num ) { cancellable threads . execute io ( send batch ) ; } assert expected total ops = = snapshot . skipped operations ( ) + skipped ops + total sent ops : string . format ( locale . root , str , expected total ops , snapshot . skipped operations ( ) , skipped ops , total sent ops ) ; if ( required ops tracker . get checkpoint ( ) < ending seq no ) { throw new illegal state exception ( str + str + required seq no range start + str + ending seq no + str + ( required ops tracker . get checkpoint ( ) + num ) + str ) ; } logger . trace ( str , ops , new byte size value ( size ) , expected total ops ) ; stop watch . stop ( ) ; final time value took time = stop watch . total time ( ) ; logger . trace ( str , took time ) ; return new send snapshot result ( target local checkpoint . get ( ) , total sent ops , took time ) ; }",0.2613995174566905,3378,0
apache_commons-cli-8-6627,read - only list of option objects in this descriptor,read - only collection of option objects in this descriptor,public list get options ( ) { return collections . unmodifiable list ( options ) ; },public collection get options ( ) { return collections . unmodifiable collection ( short opts . values ( ) ) ; },0.521007776260376,4173,1
apache_kafka-6-333,this,new joined instance configured with the value serde,"public joined < k , v , vo > with value serde ( final serde < v > value serde ) { this . value serde = value serde ; return this ; }","public joined < k , v , vo > with value serde ( final serde < v > value serde ) { return new joined < > ( key serde , value serde , other value serde , name ) ; }",0.31264026711384457,2753,0
mulesoft_mule-cookbook-0-4554,list of recently added recipes .,list of recently added ingredients .,@ processor public list < recipe > get recently added ( ) { return client . get recently added ( ) ; },@ processor public list < recipe > get recently added ( ) { return get client ( ) . get recently added ( ) ; },0.6629411379496256,591,1
vavr-io_vavr-296-1759,a checked function8,"a function that applies arguments to the given partial function and returns some ( result ) if the function is defined for the given arguments , and none otherwise .","static < t1 , t2 , t3 , t4 , t5 , t6 , t7 , t8 , r > checked function8 < t1 , t2 , t3 , t4 , t5 , t6 , t7 , t8 , r > lift ( checked function8 < t1 , t2 , t3 , t4 , t5 , t6 , t7 , t8 , r > method reference ) { return method reference ; }","static < t1 , t2 , t3 , t4 , t5 , t6 , t7 , t8 , r > function8 < t1 , t2 , t3 , t4 , t5 , t6 , t7 , t8 , option < r > > lift ( checked function8 < t1 , t2 , t3 , t4 , t5 , t6 , t7 , t8 , r > partial function ) { return ( t1 , t2 , t3 , t4 , t5 , t6 , t7 , t8 ) - > try . of ( ( ) - > partial function . apply ( t1 , t2 , t3 , t4 , t5 , t6 , t7 , t8 ) ) . get option ( ) ; }",0.26612322529157,1384,0
davideas_FlexibleAdapter-33-1911,"the parent position of this child item or - 1 if , child is a parent itself or not found",the parent position of this child item or - 1 if not found,public int get expandable position of ( t child ) { int index = get expandable index of ( child ) ; if ( index > = num ) return expanded items . key at ( get expandable index of ( child ) ) ; return - num ; },public int get expandable position of ( @ non null t child ) { return get global position of ( get expandable of ( child ) ) ; },0.5484916965166727,2535,1
codehaus_mrp-215-6152,the address of the symbol of vm _ address . zero ( ) if it cannot be resolved,the address of the symbol of address . zero ( ) if it cannot be resolved,public static synchronized vm _ address resolve symbol ( string symbol ) { for ( iterator i = dynamic libraries . values ( ) . iterator ( ) ; i . has next ( ) ; ) { vm _ dynamic library lib = ( vm _ dynamic library ) i . next ( ) ; vm _ address symbol address = lib . get symbol ( symbol ) ; if ( ! symbol address . is zero ( ) ) { return symbol address ; } } return vm _ address . zero ( ) ; },public static synchronized address resolve symbol ( string symbol ) { for ( iterator i = dynamic libraries . values ( ) . iterator ( ) ; i . has next ( ) ; ) { vm _ dynamic library lib = ( vm _ dynamic library ) i . next ( ) ; address symbol address = lib . get symbol ( symbol ) ; if ( ! symbol address . is zero ( ) ) { return symbol address ; } } return address . zero ( ) ; },0.7113246917724609,3871,1
jMonkeyEngine_jmonkeyengine-39-2905,"a clone of this spatial , the scene graph in its entirety is cloned and can be altered independently of the original scene graph . note that meshes of geometries are not cloned explicitly , they are shared if static , or specially cloned if animated . all controls will be cloned using the control . clone for spatial method on the clone .","a clone of this spatial , the scene graph in its entirety is cloned and can be altered independently of the original scene graph . note that meshes of geometries are not cloned explicitly , they are shared if static , or specially cloned if animated .","public spatial clone ( boolean clone material ) { try { spatial clone = ( spatial ) super . clone ( ) ; if ( world bound ! = null ) { clone . world bound = world bound . clone ( ) ; } clone . world lights = world lights . clone ( ) ; clone . local lights = local lights . clone ( ) ; clone . local lights . set owner ( clone ) ; clone . world lights . set owner ( clone ) ; clone . world transform = world transform . clone ( ) ; clone . local transform = local transform . clone ( ) ; if ( clone instanceof node ) { node node = ( node ) this ; node node clone = ( node ) clone ; node clone . children = new safe array list < spatial > ( spatial . class ) ; for ( spatial child : node . children ) { spatial child clone = child . clone ( clone material ) ; child clone . parent = node clone ; node clone . children . add ( child clone ) ; } } clone . parent = null ; clone . set bound refresh ( ) ; clone . set transform refresh ( ) ; clone . set light list refresh ( ) ; clone . controls = new safe array list < control > ( control . class ) ; for ( int i = num ; i < controls . size ( ) ; i + + ) { control new control = controls . get ( i ) . clone for spatial ( clone ) ; new control . set spatial ( clone ) ; clone . controls . add ( new control ) ; } if ( user data ! = null ) { clone . user data = ( hash map < string , savable > ) user data . clone ( ) ; } return clone ; } catch ( clone not supported exception ex ) { throw new assertion error ( ) ; } }","public spatial clone ( boolean clone material ) { cloner cloner = new cloner ( ) ; cloner . set cloned value ( parent , null ) ; if ( ! clone material ) { cloner . set clone function ( material . class , new identity clone function < material > ( ) ) ; } cloner . set clone function ( mesh . class , new identity clone function < mesh > ( ) ) ; spatial clone = cloner . clone ( this ) ; clone . set transform refresh ( ) ; clone . set light list refresh ( ) ; clone . set mat param override refresh ( ) ; return clone ; }",0.6236695547898611,3925,1
mongodb_mongo-java-driver-37-2758,the options from this builder,the settings from this builder,public mongo client options build ( ) { return new mongo client options ( this ) ; },public mongo client settings build ( ) { return new mongo client settings ( this ) ; },0.558692087729772,1127,1
graphql-java_graphql-java-7-1483,an execution result,a field value info,"protected completable future < execution result > complete field ( execution context execution context , execution strategy parameters parameters , object fetched value ) { field field = parameters . get field ( ) . get ( num ) ; graph qlobject type parent type = parameters . get type info ( ) . cast type ( graph qlobject type . class ) ; graph qlfield definition field def = get field def ( execution context . get graph qlschema ( ) , parent type , field ) ; execution type info field type info = field type info ( parameters , field def ) ; instrumentation instrumentation = execution context . get instrumentation ( ) ; instrumentation field complete parameters instrumentation params = new instrumentation field complete parameters ( execution context , parameters , field def , field type info , fetched value ) ; instrumentation context < execution result > ctx complete field = instrumentation . begin field complete ( instrumentation params ) ; graphql field visibility field visibility = execution context . get graph qlschema ( ) . get field visibility ( ) ; map < string , object > argument values = values resolver . get argument values ( field visibility , field def . get arguments ( ) , field . get arguments ( ) , execution context . get variables ( ) ) ; non nullable field validator non nullable field validator = new non nullable field validator ( execution context , field type info ) ; execution strategy parameters new parameters = parameters . transform ( builder - > builder . type info ( field type info ) . arguments ( argument values ) . source ( fetched value ) . non null field validator ( non nullable field validator ) ) ; log . debug ( str , execution context . get execution id ( ) , field type info . get path ( ) ) ; completable future < execution result > cf = complete value ( execution context , new parameters ) ; ctx complete field . on dispatched ( cf ) ; cf . when complete ( ctx complete field : : on completed ) ; return cf ; }","protected field value info complete field ( execution context execution context , execution strategy parameters parameters , object fetched value ) { field field = parameters . get field ( ) . get ( num ) ; graph qlobject type parent type = parameters . get type info ( ) . cast type ( graph qlobject type . class ) ; graph qlfield definition field def = get field def ( execution context . get graph qlschema ( ) , parent type , field ) ; execution type info field type info = field type info ( parameters , field def ) ; instrumentation instrumentation = execution context . get instrumentation ( ) ; instrumentation field complete parameters instrumentation params = new instrumentation field complete parameters ( execution context , parameters , field def , field type info , fetched value ) ; instrumentation context < execution result > ctx complete field = instrumentation . begin field complete ( instrumentation params ) ; graphql field visibility field visibility = execution context . get graph qlschema ( ) . get field visibility ( ) ; map < string , object > argument values = values resolver . get argument values ( field visibility , field def . get arguments ( ) , field . get arguments ( ) , execution context . get variables ( ) ) ; non nullable field validator non nullable field validator = new non nullable field validator ( execution context , field type info ) ; execution strategy parameters new parameters = parameters . transform ( builder - > builder . type info ( field type info ) . arguments ( argument values ) . source ( fetched value ) . non null field validator ( non nullable field validator ) ) ; log . debug ( str , execution context . get execution id ( ) , field type info . get path ( ) ) ; field value info field value info = complete value ( execution context , new parameters ) ; completable future < execution result > execution result future = field value info . get field value ( ) ; ctx complete field . on dispatched ( execution result future ) ; execution result future . when complete ( ctx complete field : : on completed ) ; return field value info ; }",0.2647579212983449,3281,0
apache_commons-collections-222-5085,"a new iterable , interleaving this iterable with the elements","a new iterable , interleaving this iterable with others",@ suppress warnings ( str ) public fluent iterable < e > zip ( final e . . . elements ) { return zip ( arrays . as list ( elements ) ) ; },"public fluent iterable < e > zip ( final iterable < ? extends e > other ) { return of ( iterable utils . zipping iterable ( iterable , other ) ) ; }",0.5741314689318339,1195,1
rwl_requestfactory-addon-6-5311,the element if discovered ( null if not found ),the node if discovered ( null if not found ),"public static attr find first attribute ( string x path expression , element element ) { attr attr = null ; try { xpath expression expr = compiled expression cache . get ( x path expression ) ; if ( expr = = null ) { expr = xpath . compile ( x path expression ) ; compiled expression cache . put ( x path expression , expr ) ; } attr = ( attr ) expr . evaluate ( element , xpath constants . node ) ; } catch ( xpath expression exception e ) { throw new illegal argument exception ( str , e ) ; } return attr ; }","public static node find first attribute ( string x path expression , element element ) { node attr = null ; try { xpath expression expr = compiled expression cache . get ( x path expression ) ; if ( expr = = null ) { expr = xpath . compile ( x path expression ) ; compiled expression cache . put ( x path expression , expr ) ; } attr = ( node ) expr . evaluate ( element , xpath constants . node ) ; } catch ( xpath expression exception e ) { throw new illegal argument exception ( str , e ) ; } return attr ; }",0.4301955650250117,2525,1
real-logic_aeron-86-1238,true if there is availability otherwise false .,number of bytes available,"public boolean scan for availability ( final unsafe buffer term buffer , final int offset , int max length ) { max length = math . min ( max length , term buffer . capacity ( ) - offset ) ; int available = num ; int padding = num ; do { final int frame offset = offset + available ; final int frame length = frame length volatile ( term buffer , frame offset ) ; if ( num = = frame length ) { break ; } int aligned frame length = align ( frame length , frame _ alignment ) ; if ( is padding frame ( term buffer , frame offset ) ) { padding = aligned frame length - aligned header length ; aligned frame length = aligned header length ; } available + = aligned frame length ; if ( available > max length ) { available - = aligned frame length ; padding = num ; break ; } } while ( ( available + padding ) < max length ) ; this . available = available ; this . padding = padding ; return available > num ; }","public int scan for availability ( final unsafe buffer term buffer , final int offset , int max length ) { max length = math . min ( max length , term buffer . capacity ( ) - offset ) ; int available = num ; int padding = num ; do { final int frame offset = offset + available ; final int frame length = frame length volatile ( term buffer , frame offset ) ; if ( num = = frame length ) { break ; } int aligned frame length = align ( frame length , frame _ alignment ) ; if ( is padding frame ( term buffer , frame offset ) ) { padding = aligned frame length - aligned header length ; aligned frame length = aligned header length ; } available + = aligned frame length ; if ( available > max length ) { available - = aligned frame length ; padding = num ; break ; } } while ( ( available + padding ) < max length ) ; this . available = available ; this . padding = padding ; return available ; }",0.29920411109924316,2476,0
vavr-io_vavr-531-1883,a new parsers . quantifier .,a new parser . quantifier .,"@ safe varargs public static parsers . quantifier _ 0 _ n ( supplier < parser > . . . parsers ) { return quantifier ( parsers , parsers . quantifier . bounds . zero _ to _ n ) ; }","@ safe varargs public static parser . quantifier _ 0 _ n ( supplier < parser > . . . parsers ) { return quantifier ( parsers , parser . quantifier . bounds . zero _ to _ n ) ; }",0.7125096321105957,3818,1
eclipse_riena-204-4995,the collection,the iterable,public static < t > iterable < t > able ( final collection < t > collection ) { if ( collection = = null ) { return collections . empty list ( ) ; } return collection ; },public static < t > iterable < t > able ( final iterable < t > iterable ) { if ( iterable = = null ) { return collections . empty list ( ) ; } return iterable ; },0.5170253316561381,4818,1
apache_lucene-solr-1-2420,"true if this replica can become leader , false if otherwise","true if core node name can become leader , false if otherwise",public boolean can become leader ( string core node name ) { return terms . can become leader ( core node name ) ; },boolean can become leader ( string core node name ) { return have highest term value ( core node name ) & & ! values . contains key ( core node name + str ) ; },0.7259714603424072,4566,1
vavr-io_vavr-139-1663,the given wide function instance as narrowed type function5,the given f instance as narrowed type function5,"@ suppress warnings ( str ) static < t1 , t2 , t3 , t4 , t5 , r > function5 < t1 , t2 , t3 , t4 , t5 , r > narrow ( function5 < ? super t1 , ? super t2 , ? super t3 , ? super t4 , ? super t5 , ? extends r > wide function ) { return ( function5 < t1 , t2 , t3 , t4 , t5 , r > ) wide function ; }","@ suppress warnings ( str ) static < t1 , t2 , t3 , t4 , t5 , r > function5 < t1 , t2 , t3 , t4 , t5 , r > narrow ( function5 < ? super t1 , ? super t2 , ? super t3 , ? super t4 , ? super t5 , ? extends r > f ) { return ( function5 < t1 , t2 , t3 , t4 , t5 , r > ) f ; }",0.7276291847229004,1701,1
pmd_pmd-36-2718,string [ ],the legal package names,public string [ ] legal package names ( ) { return legal package names ; },"public string [ ] legal package names ( ) { return arrays . copy of ( legal package names , legal package names . length ) ; }",0.3315584162871043,4419,0
eclipse_jetty.project-244-6608,"the header with the given name , or null if no such header exists","the field with the given name , or null if no such field exists",public header get ( string name ) { return headers . get ( name . trim ( ) . to lower case ( ) ) ; },public field get ( string name ) { return fields . get ( name . trim ( ) . to lower case ( ) ) ; },0.6271016001701355,533,1
adragomir_hbaseindex-38-5497,- array byte values,array of cells .,"public cell [ ] get ( final byte [ ] row , final byte [ ] column , final int num versions ) throws ioexception { cell [ ] values = null ; values = connection . get region server with retries ( new server callable < cell [ ] > ( connection , table name , row ) { public cell [ ] call ( ) throws ioexception { return server . get ( location . get region info ( ) . get region name ( ) , row , column , num versions ) ; } } ) ; if ( values ! = null ) { array list < cell > cell values = new array list < cell > ( ) ; for ( int i = num ; i < values . length ; i + + ) { cell values . add ( values [ i ] ) ; } return cell values . to array ( new cell [ values . length ] ) ; } return null ; }","public cell [ ] get ( final byte [ ] row , final byte [ ] column , final int num versions ) throws ioexception { return connection . get region server with retries ( new server callable < cell [ ] > ( connection , table name , row ) { public cell [ ] call ( ) throws ioexception { return server . get ( location . get region info ( ) . get region name ( ) , row , column , num versions ) ; } } ) ; }",0.2717616558074951,2890,0
apache_stanbol-80-6122,the uri of the element as clerezza uri ref,the uri of the element as clerezza iri,public uri ref get uri ( ) { return uri ; },public iri get uri ( ) { return uri ; },1.0000001192092896,2791,1
apache_axis2-java-348-4438,returns operation context operation context,"an active operation context , or null",public operation context get operation context ( string id ) { operation context op ctx = ( operation context ) this . operation context map . get ( id ) ; return op ctx ; },public operation context get operation context ( string message id ) { return ( operation context ) this . operation context map . get ( message id ) ; },0.6143957277139028,339,1
eclipse_gmp.graphiti-1-7038,the integer - value for the given hexadecimal character .,the integer representation of the hexadecimal string,private static int hex to int ( char hex char ) throws number format exception { switch ( hex char ) { case str : return num ; case str : return num ; case str : return num ; case str : return num ; case str : return num ; case str : return num ; case str : return num ; case str : return num ; case str : return num ; case str : return num ; case str : return num ; case str : return num ; case str : return num ; case str : return num ; case str : return num ; case str : return num ; case str : return num ; case str : return num ; case str : return num ; case str : return num ; case str : return num ; case str : return num ; } throw new number format exception ( str + ( int ) hex char ) ; },"private static int hex to int ( string hex string ) { return integer . value of ( hex string , num ) ; }",0.6291081309318542,1176,1
mulesoft_mule-extensions-api-26-5453,true,false,@ override public boolean is externalizable ( ) { return true ; },@ override public boolean is externalizable ( ) { return false ; },0.3267257163921992,3828,0
mulesoft_mule-411-7268,expected number of events or - 1 if no expected size was specified .,expected number of events or null if no expected size was specified .,public int expected size ( ) { return expected size ; },public integer expected size ( ) { return expected size ; },0.7750910321871439,981,1
mhl_libbio-formats-java-74-6584,hashtable of the first well ' s ifds .,list of the first well ' s ifds .,private hashtable [ ] first well ifds ( ) { for ( int i = num ; i < ifds . length ; i + + ) { for ( int j = num ; j < ifds [ i ] . length ; j + + ) { if ( ifds [ i ] [ j ] ! = null ) { return ifds [ i ] [ j ] ; } } } return null ; },private ifdlist first well ifds ( ) { for ( int i = num ; i < ifds . length ; i + + ) { for ( int j = num ; j < ifds [ i ] . length ; j + + ) { if ( ifds [ i ] [ j ] ! = null ) return ifds [ i ] [ j ] ; } } return null ; },0.7352180480957031,1641,1
joyent_java-manta-21-6530,"error code , if unavailable the value of unknown _ server _ code",error code as an enum,public string get server code ( ) { return this . server code ; },public manta error code get server code ( ) { return this . server code ; },0.4559645851453145,4618,1
eclipse-vertx_vert.x-23-556,the current argument model instance,the current argument instance,public argument model set default value ( string default value ) { this . default value = default value ; return this ; },public argument set default value ( string default value ) { this . default value = default value ; return this ; },0.5881584088007609,2209,1
jMonkeyEngine_jmonkeyengine-33-2899,true if point sprite mode is enabled .,true,public boolean is point sprite ( ) { return point sprite ; },@ deprecated public boolean is point sprite ( ) { return true ; },0.33750595649083454,3405,0
imace_de.cau.cs.kieler-887-4349,whether a view with the given identifier has been updated,the view with the identifier or null on failure,"public boolean update view ( final string id , final string name , final object model ) { iworkbench window window = platform ui . get workbench ( ) . get active workbench window ( ) ; iworkbench page page = window . get active page ( ) ; iview reference view ref = page . find view reference ( primary _ view _ id , id ) ; if ( view ref ! = null ) { iview part view = view ref . get view ( true ) ; if ( view instanceof diagram view part ) { diagram view part diagram view = ( diagram view part ) view ; if ( name ! = null ) { diagram view . set name ( name ) ; } if ( model ! = null ) { page . bring to top ( diagram view ) ; view context view context = light diagram services . get instance ( ) . create view context ( model ) ; diagram view . get viewer ( ) . set model ( view context ) ; } return true ; } } return false ; }","public diagram view part update view ( final string id , final string name , final object model , final iproperty holder property holder ) { register part listener ( ) ; iworkbench window window = platform ui . get workbench ( ) . get active workbench window ( ) ; iworkbench page page = window . get active page ( ) ; diagram view part diagram view = get view ( id ) ; view context view context = id context mapping . get ( id ) ; if ( diagram view ! = null & & view context ! = null ) { if ( name ! = null ) { diagram view . set name ( name ) ; } if ( model ! = null ) { page . bring to top ( diagram view ) ; if ( ! light diagram services . get instance ( ) . update view context ( view context , model , property holder ) ) { return null ; } } return diagram view ; } return null ; }",0.28125108778476715,5616,0
jcs_logicmail-30-6085,list of returned strings,table of returned strings,"public vector execute extended hello ( string domain ) throws ioexception , mail exception { if ( event logger . get minimum level ( ) > = event logger . debug _ info ) { event logger . log event ( app info . guid , ( str + domain + str ) . get bytes ( ) , event logger . debug _ info ) ; } string [ ] result = execute follow ( str + domain ) ; vector items = new vector ( ) ; for ( int i = num ; i < result . length ; i + + ) { if ( result [ i ] . length ( ) > num ) { items . add element ( result [ i ] . substring ( num ) ) ; } } return items ; }","public hashtable execute extended hello ( string domain ) throws ioexception , mail exception { if ( event logger . get minimum level ( ) > = event logger . debug _ info ) { event logger . log event ( app info . guid , ( str + domain + str ) . get bytes ( ) , event logger . debug _ info ) ; } string [ ] result = execute follow ( str + domain ) ; hashtable items = new hashtable ( ) ; for ( int i = num ; i < result . length ; i + + ) { if ( result [ i ] . length ( ) > num ) { items . put ( result [ i ] . substring ( num ) , boolean . true ) ; } } return items ; }",0.3315235525369644,6004,0
apache_myfaces-html5-0-4566,true if the regex validator is found an the pattern markup is written . false otherwise .,true if a pattern is found or calculated and the pattern markup is written . false otherwise .,"public static boolean render pattern ( faces context faces context , uiinput component ) throws ioexception { validator [ ] validators = component . get validators ( ) ; for ( validator validator : validators ) { if ( validator instanceof regex validator ) { regex validator regex validator = ( regex validator ) validator ; string pattern = regex validator . get pattern ( ) ; response writer writer = faces context . get response writer ( ) ; writer . write attribute ( html5 . pattern _ attr , pattern , null ) ; return true ; } } return false ; }","public static boolean render pattern ( faces context faces context , uiinput component ) throws ioexception { string pattern = null ; pattern = _ get pattern from validators ( component . get validators ( ) ) ; if ( pattern = = null ) pattern = _ get pattern from converter ( component . get converter ( ) ) ; if ( pattern ! = null ) { response writer writer = faces context . get response writer ( ) ; writer . write attribute ( html5 . pattern _ attr , pattern , null ) ; return true ; } else { return false ; } }",0.5351552764574686,2962,1
Blankj_AndroidUtilCode-95-157,intent,app ( 8 . 0 ),"public static intent get install app intent ( final file file , final string authority ) { if ( file = = null ) return null ; intent intent = new intent ( intent . action _ view ) ; uri data ; string type = str ; if ( build . version . sdk _ int < build . version _ codes . n ) { data = uri . from file ( file ) ; } else { intent . set flags ( intent . flag _ grant _ read _ uri _ permission ) ; data = file provider . get uri for file ( utils . get context ( ) , authority , file ) ; } intent . set data and type ( data , type ) ; return intent . add flags ( intent . flag _ activity _ new _ task ) ; }","public static intent get install app intent ( final file file , final string authority ) { return get install app intent ( file , authority , false ) ; }",0.18995221455891928,709,0
oldmanpushcart_greys-anatomy-6-2002,true if the string is not empty and not null and not whitespace,true : / false :,public static boolean is not blank ( string str ) { return ! is blank ( str ) ; },public static boolean is not blank ( string string ) { return ! is blank ( string ) ; },0.32599587738513947,731,0
apache_commons-collections-151-5066,a string .,the property name which includes another property,public string get include ( ) { return include ; },public string get include ( ) { if ( include property name = = null ) { return include ; } if ( str . equals ( include property name ) ) { return null ; } return include property name ; },0.31871044635772705,442,0
eclipse_gef-189-6974,a list containing all node content parts ( within the currently rendered graph ) that have a nested graph assigned to them .,a list containing all node parts ( within the currently rendered graph ) that have a nested graph assigned to them .,"protected list < node content part > find nesting nodes ( ) { list < ivisual part < node , ? extends node > > root children = get host ( ) . get root ( ) . get children unmodifiable ( ) ; list < ivisual part < node , ? extends node > > graph children = root children . size ( ) > num ? root children . get ( num ) . get children unmodifiable ( ) : collections . < ivisual part < node , ? extends node > > empty list ( ) ; list < node content part > nesting node content parts = part utils . filter parts ( graph children , node content part . class ) ; for ( int i = nesting node content parts . size ( ) - num ; i > = num ; i - - ) { node content part node part = nesting node content parts . get ( i ) ; if ( node part . get content ( ) . get nested graph ( ) = = null ) { nesting node content parts . remove ( i ) ; } } return nesting node content parts ; }","protected list < node part > find nesting nodes ( ) { list < ivisual part < node , ? extends node > > root children = get host ( ) . get root ( ) . get children unmodifiable ( ) ; list < ivisual part < node , ? extends node > > graph children = root children . size ( ) > num ? root children . get ( num ) . get children unmodifiable ( ) : collections . < ivisual part < node , ? extends node > > empty list ( ) ; list < node part > nesting node content parts = part utils . filter parts ( graph children , node part . class ) ; for ( int i = nesting node content parts . size ( ) - num ; i > = num ; i - - ) { node part node part = nesting node content parts . get ( i ) ; if ( node part . get content ( ) . get nested graph ( ) = = null ) { nesting node content parts . remove ( i ) ; } } return nesting node content parts ; }",0.731168270111084,4774,1
apache_velocity-engine-30-4023,configuration configuration object which houses the velocity runtime properties .,extended properties configuration object which houses the velocity runtime properties .,public static configuration get configuration ( ) { return configuration ; },public static extended properties get configuration ( ) { return configuration ; },0.7607360482215881,2859,1
apache_directory-server-758-6773,the application request .,the ap req .,public application request get auth header ( ) { return auth header ; },public ap req get auth header ( ) { return auth header ; },0.4703056414922078,5390,1
apache_commons-lang-201-3873,"the input string , never null or empty , for chaining",the validated character sequence ( never null method for chaining ),"public static < t extends char sequence > t not empty ( t string ) { return not empty ( string , str ) ; }","public static < t extends char sequence > t not empty ( t chars ) { return not empty ( chars , default _ not _ empty _ char _ sequence _ exception _ message ) ; }",0.4978284239768982,4239,1
jenkinsci_foreman-node-sharing-plugin-5-4927,host in json form .,updated host info representing reserved host .,"@ check for null public json node reserve host ( string hostname ) throws exception { try { if ( ! is host free ( hostname ) ) { logger . info ( str + hostname + str ) ; return null ; } } catch ( exception e ) { logger . severe ( str + hostname + str ) ; return null ; } logger . info ( str + hostname ) ; web target target = base . path ( foreman _ reserve _ path ) . query param ( foreman _ query _ param , foreman _ query _ name + hostname ) . query param ( foreman _ reserve _ reason , get reserve reason ( ) ) ; logger . fine ( target . to string ( ) ) ; response response = get foreman response ( target ) ; response . status status = response . status . from status code ( response . get status ( ) ) ; if ( status = = response . status . ok ) { string response as string = response . read entity ( string . class ) ; logger . finer ( response as string ) ; try { return new object mapper ( ) . read value ( response as string , json node . class ) ; } catch ( exception e ) { logger . log ( level . severe , str + hostname + str , e ) ; throw e ; } } else { string msg = str + hostname + str + response . get status ( ) + str ; logger . severe ( msg ) ; if ( status = = response . status . not _ found | | status = = response . status . not _ acceptable ) { return null ; } else { throw new exception ( msg ) ; } } }","@ check for null public host info reserve host ( host info host ) throws exception { string hostname = host . get name ( ) ; host = get host info ( hostname ) ; if ( host = = null | | host . is reserved ( ) ) return null ; logger . info ( str + hostname ) ; string reserve reason = get reserve reason ( ) ; web target target = base . path ( foreman _ reserve _ path ) . query param ( foreman _ query _ param , foreman _ query _ name + hostname ) . query param ( foreman _ reserve _ reason , reserve reason ) ; logger . fine ( target . to string ( ) ) ; response response = get foreman response ( target ) ; response . status status = response . status . from status code ( response . get status ( ) ) ; if ( status = = response . status . ok ) { string response as string = response . read entity ( string . class ) ; logger . finer ( response as string ) ; host info reserved host = get host info ( hostname ) ; if ( reserve reason . equals ( reserved host . get reserved for ( ) ) ) { return reserved host ; } logger . info ( str + hostname + str + reserved host . get reserved for ( ) ) ; return null ; } else { string msg = str + hostname + str + response . get status ( ) + str ; logger . severe ( msg ) ; if ( status = = response . status . not _ found | | status = = response . status . not _ acceptable ) { return null ; } else { throw new exception ( msg ) ; } } }",0.5723345279693604,3020,1
OpenAPITools_openapi-generator-19-2926,map,"map & lt ; string , integer & gt ;","public map < string , integer > get inventory ( ) throws api exception { object local var post body = null ; string local var path = str . replace all ( str , str ) ; list < pair > local var query params = new array list < pair > ( ) ; map < string , string > local var header params = new hash map < string , string > ( ) ; map < string , object > local var form params = new hash map < string , object > ( ) ; final string [ ] local var accepts = { str } ; final string local var accept = api client . select header accept ( local var accepts ) ; final string [ ] local var content types = { } ; final string local var content type = api client . select header content type ( local var content types ) ; string [ ] local var auth names = new string [ ] { str } ; generic type < map < string , integer > > local var return type = new generic type < map < string , integer > > ( ) { } ; return api client . invoke api ( local var path , str , local var query params , local var post body , local var header params , local var form params , local var accept , local var content type , local var auth names , local var return type ) ; }","public map < string , integer > get inventory ( ) throws api exception { object local var post body = null ; string local var path = str ; list < pair > local var query params = new array list < pair > ( ) ; list < pair > local var collection query params = new array list < pair > ( ) ; map < string , string > local var header params = new hash map < string , string > ( ) ; map < string , object > local var form params = new hash map < string , object > ( ) ; final string [ ] local var accepts = { str } ; final string local var accept = api client . select header accept ( local var accepts ) ; final string [ ] local var content types = { } ; final string local var content type = api client . select header content type ( local var content types ) ; string [ ] local var auth names = new string [ ] { str } ; generic type < map < string , integer > > local var return type = new generic type < map < string , integer > > ( ) { } ; return api client . invoke api ( local var path , str , local var query params , local var collection query params , local var post body , local var header params , local var form params , local var accept , local var content type , local var auth names , local var return type ) ; }",0.10735580449302991,3811,0
deeplearning4j_deeplearning4j-168-468,the the discrete fourier apply transform to origin of the passed in input,the the discrete fourier transform of the passed in input,"public static icomplex ndarray ifft ( icomplex ndarray input c ) { if ( input c . is vector ( ) ) return new vector ifft ( input c . length ( ) ) . apply ( input c ) ; else { return rawifft ( input c , input c . size ( input c . shape ( ) . length - num ) , input c . shape ( ) . length - num ) ; } }",public static icomplex ndarray ifft ( icomplex ndarray input c ) { return nd4j . get fft ( ) . ifft ( input c ) ; },0.47493276993433636,3337,1
apache_httpcomponents-client-103-5953,http response that was constructed,simple http response constructed response,"classic http response generate response ( final http request request , final http cache entry entry ) { final date now = new date ( ) ; final classic http response response = new basic classic http response ( entry . get status ( ) ) ; response . set version ( http version . default ) ; response . set headers ( entry . get all headers ( ) ) ; if ( response should contain entity ( request , entry ) ) { final http entity entity = new cache entity ( entry ) ; add missing content length header ( response , entity ) ; response . set entity ( entity ) ; } final long age = this . validity strategy . get current age secs ( entry , now ) ; if ( age > num ) { if ( age > = integer . max _ value ) { response . set header ( header constants . age , str ) ; } else { response . set header ( header constants . age , str + ( ( int ) age ) ) ; } } return response ; }","simple http response generate response ( final http request request , final http cache entry entry ) throws ioexception { final date now = new date ( ) ; final simple http response response = new simple http response ( entry . get status ( ) ) ; response . set version ( http version . default ) ; response . set headers ( entry . get all headers ( ) ) ; if ( response should contain entity ( request , entry ) ) { final resource resource = entry . get resource ( ) ; final header h = entry . get first header ( http headers . content _ type ) ; final content type content type = h ! = null ? content type . parse ( h . get value ( ) ) : null ; final byte [ ] content = resource . get ( ) ; add missing content length header ( response , content ) ; response . set body bytes ( content , content type ) ; } final long age = this . validity strategy . get current age secs ( entry , now ) ; if ( age > num ) { if ( age > = integer . max _ value ) { response . set header ( header constants . age , str ) ; } else { response . set header ( header constants . age , str + ( ( int ) age ) ) ; } } return response ; }",0.4447011003891627,3032,1
mpusher_mpush-0-2357,- 1,entry entry - 1,public static long get duration ( ) { if ( enabled ) { entry entry = ( entry ) entry stack . get ( ) ; if ( entry ! = null ) { return entry . get duration ( ) ; } else { return - num ; } } return - num ; },public long get duration ( ) { if ( end time < start time ) { return - num ; } else { return end time - start time ; } },0.27316826581954956,2948,0
facebook_buck-124-6261,a symlink tree for the exported headers of this prebuilt c / c + + library .,a header symlink tree for the exported headers of this prebuilt c / c + + library .,"public static < a extends arg > symlink tree create exported header symlink tree build rule ( build rule params params , build rule resolver resolver , cxx platform cxx platform , a args ) { return cxx description enhancer . create header symlink tree ( params , resolver , new source path resolver ( resolver ) , cxx platform , false , immutable map . < string , source path > of ( ) , immutable map . < string , source path > of ( ) , parse exported headers ( params , resolver , cxx platform , args ) , header visibility . public ) ; }","public static < a extends arg > header symlink tree create exported header symlink tree build rule ( build rule params params , build rule resolver resolver , cxx platform cxx platform , a args ) { return cxx description enhancer . create header symlink tree ( params , resolver , new source path resolver ( resolver ) , cxx platform , false , immutable map . < string , source path > of ( ) , immutable map . < string , source path > of ( ) , parse exported headers ( params , resolver , cxx platform , args ) , header visibility . public ) ; }",0.7196971575419108,654,1
apache_hadoop-37-610,instance of ksm bucket args,instance of om bucket args,"public static ksm bucket args get from protobuf ( bucket args bucket args ) { return new ksm bucket args ( bucket args . get volume name ( ) , bucket args . get bucket name ( ) , bucket args . get add acls list ( ) . stream ( ) . map ( ksmpbhelper : : convert ozone acl ) . collect ( collectors . to list ( ) ) , bucket args . get remove acls list ( ) . stream ( ) . map ( ksmpbhelper : : convert ozone acl ) . collect ( collectors . to list ( ) ) , bucket args . has is version enabled ( ) ? bucket args . get is version enabled ( ) : null , bucket args . has storage type ( ) ? pbhelper client . convert storage type ( bucket args . get storage type ( ) ) : null ) ; }","public static om bucket args get from protobuf ( bucket args bucket args ) { return new om bucket args ( bucket args . get volume name ( ) , bucket args . get bucket name ( ) , bucket args . get add acls list ( ) . stream ( ) . map ( ompbhelper : : convert ozone acl ) . collect ( collectors . to list ( ) ) , bucket args . get remove acls list ( ) . stream ( ) . map ( ompbhelper : : convert ozone acl ) . collect ( collectors . to list ( ) ) , bucket args . has is version enabled ( ) ? bucket args . get is version enabled ( ) : null , bucket args . has storage type ( ) ? pbhelper client . convert storage type ( bucket args . get storage type ( ) ) : null ) ; }",0.4914868474006653,5709,1
